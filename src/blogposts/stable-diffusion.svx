---
title: Playing Around with Stable Diffusion
date: 2023-05-06
desc: Dipping my toes into txt2img
slug: stable-diffusion
tags:
  - ai
  - art
  - stable-diffusion
---

If you have been following for a while now, you may have noticed that I sometimes include images in my posts.
Some of these have been generated by AI, specifically Midjourney. Using Midjourney for the first time completely blew me away.

I have been avidly playing around with this cutting-edge technology for a while now. Stable Diffusion has been my primary driver.
I've got AUTO1111's client setup locally and ~60GB (which is actually very little) of various Stable Diffusion checkpoints and a bunch of LoRA models.
My GTX1660 6GB GPU has put up with more than I expected. These workloads can easily consume >8GB VRAM and my barebones unoptimized workflow doesn't help - if I can even call it that.

Honestly, I'm just kind of staggering about. Generate an amazing image and admire it here and there, explore tools people have open sourced, come across things I know absolutely nothing about, learn about prompt engineering.
There is just so much! Things in this space are moving **crazy** fast - don't be surprised if a guide created only a month ago no longer works. Great fun.


Some notable things I've spent my time on:
- Going through a [practical deep learning course](https://course.fast.ai/) created by the folks at fast.ai
- Breaking open the blackbox. Calculus. Intuition. [3Blue1Brown - The Essence of Calculus](https://www.youtube.com/watch?v=WUvTyaaNkzM&list=PL0-GT3co4r2wlh6UHTUeQsrf3mlS2lk6x)
- Many attempts training an art-style LoRA. Miraculously got one with decent results in the end.
    - Check it out! [ttgl-eyecatch-LoRA](https://github.com/jamszh/ttgl-eyecatch-LoRA)

I plan to continue all this, but I think my GPU is reaching its limits.
I'm unsure as to whether I should fork out some ðŸ’°  for a more powerful GPU or to simply get google colab subscription.

I'll probably just wait until I finish the fast.ai course.
